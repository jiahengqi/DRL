{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "MAXSTEP=500\n",
    "convergence_reward = 475\n",
    "VERSION='nips dueling'\n",
    "\n",
    "\n",
    "np.random.seed(1024)\n",
    "tf.set_random_seed(1024)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class duel_double_dqn:\n",
    "    def __init__(self, env, hidden_units=20, maxlen=10000, batch_size=32, \n",
    "                 explore_init=0.5, explore_end=0.01, explore_steps=100000,\n",
    "                 update_fre=20, gamma=0.99, train_times=1, version='double'):\n",
    "        self.env=env\n",
    "        self.batch_size=batch_size\n",
    "        self.explore=explore_init\n",
    "        self.explore_init=explore_init\n",
    "        self.explore_end=explore_end\n",
    "        self.explore_steps=explore_steps\n",
    "        self.update_fre=update_fre\n",
    "        self.gamma=gamma\n",
    "        self.train_times=train_times\n",
    "        self.version=version\n",
    "        \n",
    "        self.model=self.create_model(hidden_units)\n",
    "        if self.version.find('nips')<0:\n",
    "            self.target_model=self.create_model(hidden_units)\n",
    "        self.memory=Memory(maxlen)\n",
    "        self.time_stamp=0\n",
    "        \n",
    "    def create_model(self, hidden_units):\n",
    "        x=Input(self.env.observation_space.shape)\n",
    "        h=Dense(hidden_units, activation='tanh')(x)\n",
    "        if self.version.find('duel')>-1:\n",
    "            a=Dense(self.env.action_space.n,)(h)\n",
    "            v=Dense(1,)(h)\n",
    "            z=Lambda(lambda a:a[0]+a[1]-K.mean(a[1],keepdims=True))([v,a])\n",
    "        else:\n",
    "            z=Dense(self.env.action_space.n,)(h)\n",
    "        model=Model(inputs=x, outputs=z)\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def update(self):\n",
    "        self.time_stamp+=1\n",
    "        if len(self.memory.buffer)>=self.batch_size:\n",
    "            for _ in range(self.train_times):\n",
    "                #data=random.sample(self.memory,self.batch_size)\n",
    "                data=self.memory.sample(self.batch_size)\n",
    "                s=[d[0] for d in data]\n",
    "                a=[d[1] for d in data]\n",
    "                r=[d[2] for d in data]\n",
    "                s_=[d[3] for d in data]\n",
    "                done=[d[4] for d in data]\n",
    "                q1=self.model.predict(np.array(s))\n",
    "                if self.version.find('nips')>-1:\n",
    "                    q2=self.model.predict(np.array(s_))\n",
    "                else:\n",
    "                    q2=self.target_model.predict(np.array(s_))\n",
    "                for i in range(self.batch_size):\n",
    "                    if done[i]:\n",
    "                        q1[i,a[i]]=r[i]\n",
    "                    else:\n",
    "                        if self.version.find('double')>-1:\n",
    "                            q1[i,a[i]]=r[i]+self.gamma*q2[i, np.argmax(q1[i])]\n",
    "                        else:\n",
    "                            q1[i,a[i]]=r[i]+self.gamma*np.max(q2[i])\n",
    "                self.model.train_on_batch(np.array(s),q1)\n",
    "        if self.version.find('nips')<0 and self.time_stamp%self.update_fre==0:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def store(self, s, a, r, s_, done):\n",
    "        #self.memory.append([s,a,r,s_,done])\n",
    "        self.memory.add((s, a, r, s_, done))\n",
    "        \n",
    "    def get_action(self, s, flag=True):\n",
    "        if flag:\n",
    "            if self.explore>self.explore_end:\n",
    "                self.explore-=(self.explore_init-self.explore_end)/self.explore_steps\n",
    "            if np.random.rand()<self.explore:\n",
    "                return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(s[np.newaxis,:],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-28 17:17:56,097] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Mean test reward: 9.0\n",
      "Episode: 2 Mean test reward: 8.5\n",
      "Episode: 3 Mean test reward: 8.3\n",
      "Episode: 4 Mean test reward: 8.2\n",
      "Episode: 5 Mean test reward: 8.2\n",
      "Episode: 6 Mean test reward: 8.3\n",
      "Episode: 7 Mean test reward: 8.4\n",
      "Episode: 8 Mean test reward: 8.5\n",
      "Episode: 9 Mean test reward: 8.4\n",
      "Episode: 10 Mean test reward: 8.5\n",
      "Episode: 11 Mean test reward: 8.5\n",
      "Episode: 12 Mean test reward: 8.4\n",
      "Episode: 13 Mean test reward: 8.4\n",
      "Episode: 14 Mean test reward: 8.4\n",
      "Episode: 15 Mean test reward: 8.3\n",
      "Episode: 16 Mean test reward: 8.2\n",
      "Episode: 17 Mean test reward: 8.3\n",
      "Episode: 18 Mean test reward: 8.3\n",
      "Episode: 19 Mean test reward: 8.3\n",
      "Episode: 20 Mean test reward: 8.3\n",
      "Episode: 21 Mean test reward: 8.3\n",
      "Episode: 22 Mean test reward: 8.4\n",
      "Episode: 23 Mean test reward: 8.4\n",
      "Episode: 24 Mean test reward: 8.4\n",
      "Episode: 25 Mean test reward: 8.4\n",
      "Episode: 26 Mean test reward: 8.4\n",
      "Episode: 27 Mean test reward: 8.4\n",
      "Episode: 28 Mean test reward: 8.4\n",
      "Episode: 29 Mean test reward: 8.4\n",
      "Episode: 30 Mean test reward: 8.4\n",
      "Episode: 31 Mean test reward: 8.4\n",
      "Episode: 32 Mean test reward: 8.4\n",
      "Episode: 33 Mean test reward: 8.5\n",
      "Episode: 34 Mean test reward: 8.5\n",
      "Episode: 35 Mean test reward: 8.5\n",
      "Episode: 36 Mean test reward: 8.5\n",
      "Episode: 37 Mean test reward: 8.5\n",
      "Episode: 38 Mean test reward: 8.5\n",
      "Episode: 39 Mean test reward: 8.6\n",
      "Episode: 40 Mean test reward: 8.7\n",
      "Episode: 41 Mean test reward: 8.8\n",
      "Episode: 42 Mean test reward: 8.9\n",
      "Episode: 43 Mean test reward: 9.1\n",
      "Episode: 44 Mean test reward: 9.2\n",
      "Episode: 45 Mean test reward: 9.4\n",
      "Episode: 46 Mean test reward: 9.6\n",
      "Episode: 47 Mean test reward: 10.0\n",
      "Episode: 48 Mean test reward: 10.2\n",
      "Episode: 49 Mean test reward: 10.6\n",
      "Episode: 50 Mean test reward: 11.2\n",
      "Episode: 51 Mean test reward: 11.6\n",
      "Episode: 52 Mean test reward: 12.3\n",
      "Episode: 53 Mean test reward: 12.8\n",
      "Episode: 54 Mean test reward: 13.5\n",
      "Episode: 55 Mean test reward: 14.6\n",
      "Episode: 56 Mean test reward: 15.5\n",
      "Episode: 57 Mean test reward: 20.2\n",
      "Episode: 58 Mean test reward: 23.6\n",
      "Episode: 59 Mean test reward: 25.2\n",
      "Episode: 60 Mean test reward: 28.4\n",
      "Episode: 61 Mean test reward: 29.5\n",
      "Episode: 62 Mean test reward: 29.7\n",
      "Episode: 63 Mean test reward: 29.8\n",
      "Episode: 64 Mean test reward: 30.1\n",
      "Episode: 65 Mean test reward: 30.2\n",
      "Episode: 66 Mean test reward: 30.4\n",
      "Episode: 67 Mean test reward: 31.3\n",
      "Episode: 68 Mean test reward: 31.2\n",
      "Episode: 69 Mean test reward: 31.3\n",
      "Episode: 70 Mean test reward: 31.2\n",
      "Episode: 71 Mean test reward: 31.3\n",
      "Episode: 72 Mean test reward: 31.2\n",
      "Episode: 73 Mean test reward: 31.0\n",
      "Episode: 74 Mean test reward: 30.9\n",
      "Episode: 75 Mean test reward: 30.8\n",
      "Episode: 76 Mean test reward: 30.7\n",
      "Episode: 77 Mean test reward: 30.8\n",
      "Episode: 78 Mean test reward: 30.7\n",
      "Episode: 79 Mean test reward: 30.5\n",
      "Episode: 80 Mean test reward: 30.4\n",
      "Episode: 81 Mean test reward: 30.2\n",
      "Episode: 82 Mean test reward: 30.2\n",
      "Episode: 83 Mean test reward: 30.1\n",
      "Episode: 84 Mean test reward: 30.4\n",
      "Episode: 85 Mean test reward: 30.4\n",
      "Episode: 86 Mean test reward: 30.6\n",
      "Episode: 87 Mean test reward: 31.0\n",
      "Episode: 88 Mean test reward: 31.4\n",
      "Episode: 89 Mean test reward: 31.9\n",
      "Episode: 90 Mean test reward: 32.3\n",
      "Episode: 91 Mean test reward: 32.4\n",
      "Episode: 92 Mean test reward: 32.7\n",
      "Episode: 93 Mean test reward: 33.2\n",
      "Episode: 94 Mean test reward: 33.9\n",
      "Episode: 95 Mean test reward: 38.8\n",
      "Episode: 96 Mean test reward: 39.5\n",
      "Episode: 97 Mean test reward: 40.6\n",
      "Episode: 98 Mean test reward: 41.0\n",
      "Episode: 99 Mean test reward: 42.0\n",
      "Episode: 100 Mean test reward: 42.8\n",
      "Episode: 101 Mean test reward: 43.8\n",
      "Episode: 102 Mean test reward: 47.5\n",
      "Episode: 103 Mean test reward: 49.0\n",
      "Episode: 104 Mean test reward: 50.5\n",
      "Episode: 105 Mean test reward: 52.6\n",
      "Episode: 106 Mean test reward: 57.2\n",
      "Episode: 107 Mean test reward: 59.7\n",
      "Episode: 108 Mean test reward: 63.2\n",
      "Episode: 109 Mean test reward: 66.9\n",
      "Episode: 110 Mean test reward: 70.7\n",
      "Episode: 111 Mean test reward: 73.5\n",
      "Episode: 112 Mean test reward: 76.3\n",
      "Episode: 113 Mean test reward: 80.0\n",
      "Episode: 114 Mean test reward: 83.9\n",
      "Episode: 115 Mean test reward: 86.1\n",
      "Episode: 116 Mean test reward: 91.0\n",
      "Episode: 117 Mean test reward: 95.2\n",
      "Episode: 118 Mean test reward: 100.1\n",
      "Episode: 119 Mean test reward: 105.0\n",
      "Episode: 120 Mean test reward: 109.3\n",
      "Episode: 121 Mean test reward: 112.2\n",
      "Episode: 122 Mean test reward: 115.1\n",
      "Episode: 123 Mean test reward: 117.7\n",
      "Episode: 124 Mean test reward: 122.6\n",
      "Episode: 125 Mean test reward: 126.5\n",
      "Episode: 126 Mean test reward: 131.3\n",
      "Episode: 127 Mean test reward: 135.8\n",
      "Episode: 128 Mean test reward: 139.8\n",
      "Episode: 129 Mean test reward: 144.7\n",
      "Episode: 130 Mean test reward: 147.3\n",
      "Episode: 131 Mean test reward: 149.7\n",
      "Episode: 132 Mean test reward: 152.8\n",
      "Episode: 133 Mean test reward: 156.1\n",
      "Episode: 134 Mean test reward: 161.0\n",
      "Episode: 135 Mean test reward: 164.5\n",
      "Episode: 136 Mean test reward: 168.8\n",
      "Episode: 137 Mean test reward: 173.7\n",
      "Episode: 138 Mean test reward: 177.2\n",
      "Episode: 139 Mean test reward: 179.9\n",
      "Episode: 140 Mean test reward: 184.8\n",
      "Episode: 141 Mean test reward: 189.6\n",
      "Episode: 142 Mean test reward: 192.3\n",
      "Episode: 143 Mean test reward: 195.5\n",
      "Episode: 144 Mean test reward: 199.3\n",
      "Episode: 145 Mean test reward: 201.6\n",
      "Episode: 146 Mean test reward: 203.9\n",
      "Episode: 147 Mean test reward: 208.5\n",
      "Episode: 148 Mean test reward: 210.7\n",
      "Episode: 149 Mean test reward: 213.1\n",
      "Episode: 150 Mean test reward: 215.2\n",
      "Episode: 151 Mean test reward: 217.6\n",
      "Episode: 152 Mean test reward: 219.2\n",
      "Episode: 153 Mean test reward: 223.6\n",
      "Episode: 154 Mean test reward: 225.3\n",
      "Episode: 155 Mean test reward: 229.1\n",
      "Episode: 156 Mean test reward: 231.4\n",
      "Episode: 157 Mean test reward: 230.6\n",
      "Episode: 158 Mean test reward: 231.1\n",
      "Episode: 159 Mean test reward: 232.7\n",
      "Episode: 160 Mean test reward: 233.8\n",
      "Episode: 161 Mean test reward: 237.9\n",
      "Episode: 162 Mean test reward: 239.8\n",
      "Episode: 163 Mean test reward: 242.1\n",
      "Episode: 164 Mean test reward: 246.6\n",
      "Episode: 165 Mean test reward: 251.2\n",
      "Episode: 166 Mean test reward: 255.0\n",
      "Episode: 167 Mean test reward: 259.1\n",
      "Episode: 168 Mean test reward: 263.0\n",
      "Episode: 169 Mean test reward: 267.2\n",
      "Episode: 170 Mean test reward: 269.4\n",
      "Episode: 171 Mean test reward: 271.3\n",
      "Episode: 172 Mean test reward: 274.8\n",
      "Episode: 173 Mean test reward: 277.2\n",
      "Episode: 174 Mean test reward: 281.3\n",
      "Episode: 175 Mean test reward: 286.1\n",
      "Episode: 176 Mean test reward: 288.5\n",
      "Episode: 177 Mean test reward: 290.9\n",
      "Episode: 178 Mean test reward: 295.7\n",
      "Episode: 179 Mean test reward: 298.9\n",
      "Episode: 180 Mean test reward: 302.8\n",
      "Episode: 181 Mean test reward: 307.6\n",
      "Episode: 182 Mean test reward: 311.0\n",
      "Episode: 183 Mean test reward: 314.4\n",
      "Episode: 184 Mean test reward: 316.8\n",
      "Episode: 185 Mean test reward: 319.8\n",
      "Episode: 186 Mean test reward: 324.3\n",
      "Episode: 187 Mean test reward: 328.6\n",
      "Episode: 188 Mean test reward: 330.3\n",
      "Episode: 189 Mean test reward: 332.1\n",
      "Episode: 190 Mean test reward: 335.5\n",
      "Episode: 191 Mean test reward: 340.1\n",
      "Episode: 192 Mean test reward: 342.0\n",
      "Episode: 193 Mean test reward: 344.3\n",
      "Episode: 194 Mean test reward: 346.8\n",
      "Episode: 195 Mean test reward: 346.8\n",
      "Episode: 196 Mean test reward: 348.6\n",
      "Episode: 197 Mean test reward: 349.7\n",
      "Episode: 198 Mean test reward: 353.9\n",
      "Episode: 199 Mean test reward: 355.7\n",
      "Episode: 200 Mean test reward: 357.0\n",
      "Episode: 201 Mean test reward: 359.0\n",
      "Episode: 202 Mean test reward: 358.4\n",
      "Episode: 203 Mean test reward: 361.5\n",
      "Episode: 204 Mean test reward: 363.9\n",
      "Episode: 205 Mean test reward: 364.9\n",
      "Episode: 206 Mean test reward: 362.7\n",
      "Episode: 207 Mean test reward: 365.2\n",
      "Episode: 208 Mean test reward: 365.1\n",
      "Episode: 209 Mean test reward: 364.0\n",
      "Episode: 210 Mean test reward: 364.0\n",
      "Episode: 211 Mean test reward: 363.3\n",
      "Episode: 212 Mean test reward: 364.1\n",
      "Episode: 213 Mean test reward: 364.3\n",
      "Episode: 214 Mean test reward: 363.8\n",
      "Episode: 215 Mean test reward: 364.6\n",
      "Episode: 216 Mean test reward: 362.9\n",
      "Episode: 217 Mean test reward: 361.7\n",
      "Episode: 218 Mean test reward: 360.9\n",
      "Episode: 219 Mean test reward: 360.9\n",
      "Episode: 220 Mean test reward: 360.6\n",
      "Episode: 221 Mean test reward: 362.1\n",
      "Episode: 222 Mean test reward: 362.2\n",
      "Episode: 223 Mean test reward: 363.1\n",
      "Episode: 224 Mean test reward: 360.7\n",
      "Episode: 225 Mean test reward: 359.8\n",
      "Episode: 226 Mean test reward: 359.8\n",
      "Episode: 227 Mean test reward: 357.8\n",
      "Episode: 228 Mean test reward: 357.4\n",
      "Episode: 229 Mean test reward: 357.2\n",
      "Episode: 230 Mean test reward: 358.2\n",
      "Episode: 231 Mean test reward: 359.4\n",
      "Episode: 232 Mean test reward: 361.0\n",
      "Episode: 233 Mean test reward: 361.2\n",
      "Episode: 234 Mean test reward: 358.8\n",
      "Episode: 235 Mean test reward: 358.6\n",
      "Episode: 236 Mean test reward: 357.0\n",
      "Episode: 237 Mean test reward: 356.3\n",
      "Episode: 238 Mean test reward: 356.1\n",
      "Episode: 239 Mean test reward: 356.6\n",
      "Episode: 240 Mean test reward: 354.4\n",
      "Episode: 241 Mean test reward: 352.1\n",
      "Episode: 242 Mean test reward: 353.0\n",
      "Episode: 243 Mean test reward: 354.6\n",
      "Episode: 244 Mean test reward: 354.2\n",
      "Episode: 245 Mean test reward: 356.8\n",
      "Episode: 246 Mean test reward: 357.8\n",
      "Episode: 247 Mean test reward: 356.2\n",
      "Episode: 248 Mean test reward: 358.8\n",
      "Episode: 249 Mean test reward: 361.1\n",
      "Episode: 250 Mean test reward: 363.6\n",
      "Episode: 251 Mean test reward: 364.8\n",
      "Episode: 252 Mean test reward: 367.1\n",
      "Episode: 253 Mean test reward: 366.1\n",
      "Episode: 254 Mean test reward: 368.3\n",
      "Episode: 255 Mean test reward: 368.9\n",
      "Episode: 256 Mean test reward: 370.9\n",
      "Episode: 257 Mean test reward: 372.2\n",
      "Episode: 258 Mean test reward: 374.6\n",
      "Episode: 259 Mean test reward: 376.8\n",
      "Episode: 260 Mean test reward: 378.1\n",
      "Episode: 261 Mean test reward: 378.1\n",
      "Episode: 262 Mean test reward: 380.7\n",
      "Episode: 263 Mean test reward: 383.0\n",
      "Episode: 264 Mean test reward: 381.6\n",
      "Episode: 265 Mean test reward: 379.9\n",
      "Episode: 266 Mean test reward: 380.2\n",
      "Episode: 267 Mean test reward: 379.3\n",
      "Episode: 268 Mean test reward: 378.6\n",
      "Episode: 269 Mean test reward: 379.1\n",
      "Episode: 270 Mean test reward: 381.3\n",
      "Episode: 271 Mean test reward: 383.5\n",
      "Episode: 272 Mean test reward: 384.4\n",
      "Episode: 273 Mean test reward: 386.0\n",
      "Episode: 274 Mean test reward: 385.8\n",
      "Episode: 275 Mean test reward: 385.8\n",
      "Episode: 276 Mean test reward: 388.0\n",
      "Episode: 277 Mean test reward: 389.8\n",
      "Episode: 278 Mean test reward: 389.8\n",
      "Episode: 279 Mean test reward: 391.4\n",
      "Episode: 280 Mean test reward: 392.4\n",
      "Episode: 281 Mean test reward: 391.4\n",
      "Episode: 282 Mean test reward: 391.9\n",
      "Episode: 283 Mean test reward: 391.4\n",
      "Episode: 284 Mean test reward: 392.8\n",
      "Episode: 285 Mean test reward: 394.5\n",
      "Episode: 286 Mean test reward: 393.8\n",
      "Episode: 287 Mean test reward: 393.2\n",
      "Episode: 288 Mean test reward: 395.1\n",
      "Episode: 289 Mean test reward: 397.6\n",
      "Episode: 290 Mean test reward: 397.2\n",
      "Episode: 291 Mean test reward: 395.2\n",
      "Episode: 292 Mean test reward: 396.1\n",
      "Episode: 293 Mean test reward: 398.0\n",
      "Episode: 294 Mean test reward: 398.7\n",
      "Episode: 295 Mean test reward: 396.9\n",
      "Episode: 296 Mean test reward: 399.0\n",
      "Episode: 297 Mean test reward: 400.2\n",
      "Episode: 298 Mean test reward: 398.2\n",
      "Episode: 299 Mean test reward: 397.6\n",
      "Episode: 300 Mean test reward: 398.2\n",
      "Episode: 301 Mean test reward: 399.8\n",
      "Episode: 302 Mean test reward: 399.0\n",
      "Episode: 303 Mean test reward: 399.3\n",
      "Episode: 304 Mean test reward: 398.1\n",
      "Episode: 305 Mean test reward: 398.0\n",
      "Episode: 306 Mean test reward: 398.7\n",
      "Episode: 307 Mean test reward: 397.8\n",
      "Episode: 308 Mean test reward: 398.0\n",
      "Episode: 309 Mean test reward: 399.9\n",
      "Episode: 310 Mean test reward: 400.9\n",
      "Episode: 311 Mean test reward: 402.9\n",
      "Episode: 312 Mean test reward: 401.8\n",
      "Episode: 313 Mean test reward: 402.7\n",
      "Episode: 314 Mean test reward: 401.7\n",
      "Episode: 315 Mean test reward: 403.5\n",
      "Episode: 316 Mean test reward: 405.2\n",
      "Episode: 317 Mean test reward: 406.4\n",
      "Episode: 318 Mean test reward: 406.3\n",
      "Episode: 319 Mean test reward: 406.3\n",
      "Episode: 320 Mean test reward: 407.2\n",
      "Episode: 321 Mean test reward: 405.9\n",
      "Episode: 322 Mean test reward: 407.8\n",
      "Episode: 323 Mean test reward: 407.0\n",
      "Episode: 324 Mean test reward: 407.1\n",
      "Episode: 325 Mean test reward: 407.1\n",
      "Episode: 326 Mean test reward: 407.1\n",
      "Episode: 327 Mean test reward: 409.6\n",
      "Episode: 328 Mean test reward: 408.3\n",
      "Episode: 329 Mean test reward: 406.8\n",
      "Episode: 330 Mean test reward: 408.1\n",
      "Episode: 331 Mean test reward: 408.1\n",
      "Episode: 332 Mean test reward: 406.4\n",
      "Episode: 333 Mean test reward: 405.9\n",
      "Episode: 334 Mean test reward: 405.4\n",
      "Episode: 335 Mean test reward: 405.4\n",
      "Episode: 336 Mean test reward: 407.5\n",
      "Episode: 337 Mean test reward: 406.1\n",
      "Episode: 338 Mean test reward: 405.1\n",
      "Episode: 339 Mean test reward: 404.3\n",
      "Episode: 340 Mean test reward: 403.9\n",
      "Episode: 341 Mean test reward: 403.6\n",
      "Episode: 342 Mean test reward: 402.5\n",
      "Episode: 343 Mean test reward: 400.1\n",
      "Episode: 344 Mean test reward: 398.7\n",
      "Episode: 345 Mean test reward: 396.3\n",
      "Episode: 346 Mean test reward: 395.3\n",
      "Episode: 347 Mean test reward: 395.3\n",
      "Episode: 348 Mean test reward: 393.1\n",
      "Episode: 349 Mean test reward: 390.4\n",
      "Episode: 350 Mean test reward: 388.4\n",
      "Episode: 351 Mean test reward: 386.9\n",
      "Episode: 352 Mean test reward: 385.8\n",
      "Episode: 353 Mean test reward: 384.9\n",
      "Episode: 354 Mean test reward: 383.2\n",
      "Episode: 355 Mean test reward: 383.2\n",
      "Episode: 356 Mean test reward: 381.0\n",
      "Episode: 357 Mean test reward: 380.2\n",
      "Episode: 358 Mean test reward: 380.2\n",
      "Episode: 359 Mean test reward: 380.2\n",
      "Episode: 360 Mean test reward: 380.6\n",
      "Episode: 361 Mean test reward: 380.6\n",
      "Episode: 362 Mean test reward: 378.4\n",
      "Episode: 363 Mean test reward: 378.5\n",
      "Episode: 364 Mean test reward: 379.0\n",
      "Episode: 365 Mean test reward: 379.3\n",
      "Episode: 366 Mean test reward: 378.3\n",
      "Episode: 367 Mean test reward: 378.9\n",
      "Episode: 368 Mean test reward: 379.1\n",
      "Episode: 369 Mean test reward: 379.1\n",
      "Episode: 370 Mean test reward: 378.8\n",
      "Episode: 371 Mean test reward: 379.4\n",
      "Episode: 372 Mean test reward: 378.6\n",
      "Episode: 373 Mean test reward: 379.4\n",
      "Episode: 374 Mean test reward: 380.2\n",
      "Episode: 375 Mean test reward: 378.6\n",
      "Episode: 376 Mean test reward: 377.7\n",
      "Episode: 377 Mean test reward: 376.3\n",
      "Episode: 378 Mean test reward: 376.3\n",
      "Episode: 379 Mean test reward: 375.7\n",
      "Episode: 380 Mean test reward: 375.7\n",
      "Episode: 381 Mean test reward: 376.7\n",
      "Episode: 382 Mean test reward: 377.4\n",
      "Episode: 383 Mean test reward: 379.3\n",
      "Episode: 384 Mean test reward: 380.0\n",
      "Episode: 385 Mean test reward: 380.0\n",
      "Episode: 386 Mean test reward: 380.7\n",
      "Episode: 387 Mean test reward: 381.3\n",
      "Episode: 388 Mean test reward: 382.1\n",
      "Episode: 389 Mean test reward: 382.1\n",
      "Episode: 390 Mean test reward: 383.4\n",
      "Episode: 391 Mean test reward: 385.4\n",
      "Episode: 392 Mean test reward: 386.5\n",
      "Episode: 393 Mean test reward: 385.8\n",
      "Episode: 394 Mean test reward: 386.6\n",
      "Episode: 395 Mean test reward: 388.0\n",
      "Episode: 396 Mean test reward: 388.0\n",
      "Episode: 397 Mean test reward: 389.2\n",
      "Episode: 398 Mean test reward: 391.2\n",
      "Episode: 399 Mean test reward: 393.7\n",
      "Episode: 400 Mean test reward: 395.5\n",
      "Episode: 401 Mean test reward: 395.9\n",
      "Episode: 402 Mean test reward: 398.4\n",
      "Episode: 403 Mean test reward: 398.4\n",
      "Episode: 404 Mean test reward: 400.5\n",
      "Episode: 405 Mean test reward: 402.4\n",
      "Episode: 406 Mean test reward: 404.2\n",
      "Episode: 407 Mean test reward: 405.1\n",
      "Episode: 408 Mean test reward: 406.3\n",
      "Episode: 409 Mean test reward: 406.8\n",
      "Episode: 410 Mean test reward: 406.8\n",
      "Episode: 411 Mean test reward: 407.6\n",
      "Episode: 412 Mean test reward: 410.2\n",
      "Episode: 413 Mean test reward: 410.2\n",
      "Episode: 414 Mean test reward: 412.8\n",
      "Episode: 415 Mean test reward: 412.8\n",
      "Episode: 416 Mean test reward: 412.8\n",
      "Episode: 417 Mean test reward: 413.6\n",
      "Episode: 418 Mean test reward: 414.5\n",
      "Episode: 419 Mean test reward: 414.5\n",
      "Episode: 420 Mean test reward: 414.5\n",
      "Episode: 421 Mean test reward: 416.4\n",
      "Episode: 422 Mean test reward: 416.4\n",
      "Episode: 423 Mean test reward: 418.6\n",
      "Episode: 424 Mean test reward: 420.9\n",
      "Episode: 425 Mean test reward: 422.9\n",
      "Episode: 426 Mean test reward: 422.9\n",
      "Episode: 427 Mean test reward: 422.9\n",
      "Episode: 428 Mean test reward: 425.5\n",
      "Episode: 429 Mean test reward: 427.2\n",
      "Episode: 430 Mean test reward: 427.2\n",
      "Episode: 431 Mean test reward: 428.5\n",
      "Episode: 432 Mean test reward: 430.4\n",
      "Episode: 433 Mean test reward: 432.4\n",
      "Episode: 434 Mean test reward: 435.2\n",
      "Episode: 435 Mean test reward: 436.9\n",
      "Episode: 436 Mean test reward: 436.9\n",
      "Episode: 437 Mean test reward: 439.1\n",
      "Episode: 438 Mean test reward: 441.7\n",
      "Episode: 439 Mean test reward: 444.2\n",
      "Episode: 440 Mean test reward: 446.8\n",
      "Episode: 441 Mean test reward: 449.3\n",
      "Episode: 442 Mean test reward: 451.8\n",
      "Episode: 443 Mean test reward: 454.2\n",
      "Episode: 444 Mean test reward: 457.0\n",
      "Episode: 445 Mean test reward: 459.4\n",
      "Episode: 446 Mean test reward: 461.8\n",
      "Episode: 447 Mean test reward: 463.6\n",
      "Episode: 448 Mean test reward: 465.9\n",
      "Episode: 449 Mean test reward: 468.6\n",
      "Episode: 450 Mean test reward: 470.5\n",
      "Episode: 451 Mean test reward: 473.1\n",
      "Episode: 452 Mean test reward: 470.3\n",
      "Episode: 453 Mean test reward: 468.2\n",
      "Episode: 454 Mean test reward: 465.8\n",
      "Episode: 455 Mean test reward: 461.1\n",
      "Episode: 456 Mean test reward: 458.5\n",
      "Episode: 457 Mean test reward: 456.2\n",
      "Episode: 458 Mean test reward: 451.5\n",
      "Episode: 459 Mean test reward: 446.9\n",
      "Episode: 460 Mean test reward: 444.5\n",
      "Episode: 461 Mean test reward: 444.5\n",
      "Episode: 462 Mean test reward: 446.7\n",
      "Episode: 463 Mean test reward: 446.7\n",
      "Episode: 464 Mean test reward: 447.7\n",
      "Episode: 465 Mean test reward: 449.1\n",
      "Episode: 466 Mean test reward: 450.3\n",
      "Episode: 467 Mean test reward: 450.6\n",
      "Episode: 468 Mean test reward: 451.9\n",
      "Episode: 469 Mean test reward: 451.9\n",
      "Episode: 470 Mean test reward: 452.6\n",
      "Episode: 471 Mean test reward: 452.6\n",
      "Episode: 472 Mean test reward: 453.7\n",
      "Episode: 473 Mean test reward: 453.7\n",
      "Episode: 474 Mean test reward: 453.7\n",
      "Episode: 475 Mean test reward: 455.4\n",
      "Episode: 476 Mean test reward: 456.3\n",
      "Episode: 477 Mean test reward: 458.2\n",
      "Episode: 478 Mean test reward: 458.2\n",
      "Episode: 479 Mean test reward: 458.8\n",
      "Episode: 480 Mean test reward: 458.8\n",
      "Episode: 481 Mean test reward: 458.8\n",
      "Episode: 482 Mean test reward: 458.8\n",
      "Episode: 483 Mean test reward: 458.8\n",
      "Episode: 484 Mean test reward: 458.8\n",
      "Episode: 485 Mean test reward: 458.8\n",
      "Episode: 486 Mean test reward: 458.7\n",
      "Episode: 487 Mean test reward: 458.7\n",
      "Episode: 488 Mean test reward: 458.7\n",
      "Episode: 489 Mean test reward: 458.7\n",
      "Episode: 490 Mean test reward: 458.7\n",
      "Episode: 491 Mean test reward: 458.7\n",
      "Episode: 492 Mean test reward: 459.1\n",
      "Episode: 493 Mean test reward: 459.9\n",
      "Episode: 494 Mean test reward: 459.9\n",
      "Episode: 495 Mean test reward: 460.3\n",
      "Episode: 496 Mean test reward: 460.3\n",
      "Episode: 497 Mean test reward: 460.3\n",
      "Episode: 498 Mean test reward: 460.3\n",
      "Episode: 499 Mean test reward: 460.3\n",
      "Episode: 500 Mean test reward: 460.3\n",
      "Episode: 501 Mean test reward: 460.3\n",
      "Episode: 502 Mean test reward: 460.3\n",
      "Episode: 503 Mean test reward: 460.3\n",
      "Episode: 504 Mean test reward: 460.5\n",
      "Episode: 505 Mean test reward: 460.5\n",
      "Episode: 506 Mean test reward: 460.5\n",
      "Episode: 507 Mean test reward: 460.5\n",
      "Episode: 508 Mean test reward: 460.5\n",
      "Episode: 509 Mean test reward: 460.5\n",
      "Episode: 510 Mean test reward: 460.5\n",
      "Episode: 511 Mean test reward: 460.5\n",
      "Episode: 512 Mean test reward: 460.5\n",
      "Episode: 513 Mean test reward: 460.5\n",
      "Episode: 514 Mean test reward: 460.5\n",
      "Episode: 515 Mean test reward: 460.5\n",
      "Episode: 516 Mean test reward: 460.5\n",
      "Episode: 517 Mean test reward: 460.5\n",
      "Episode: 518 Mean test reward: 460.5\n",
      "Episode: 519 Mean test reward: 460.5\n",
      "Episode: 520 Mean test reward: 460.5\n",
      "Episode: 521 Mean test reward: 460.5\n",
      "Episode: 522 Mean test reward: 460.5\n",
      "Episode: 523 Mean test reward: 460.5\n",
      "Episode: 524 Mean test reward: 460.5\n",
      "Episode: 525 Mean test reward: 460.5\n",
      "Episode: 526 Mean test reward: 460.5\n",
      "Episode: 527 Mean test reward: 460.5\n",
      "Episode: 528 Mean test reward: 460.5\n",
      "Episode: 529 Mean test reward: 460.5\n",
      "Episode: 530 Mean test reward: 460.5\n",
      "Episode: 531 Mean test reward: 460.5\n",
      "Episode: 532 Mean test reward: 460.5\n",
      "Episode: 533 Mean test reward: 460.5\n",
      "Episode: 534 Mean test reward: 460.5\n",
      "Episode: 535 Mean test reward: 460.5\n",
      "Episode: 536 Mean test reward: 460.5\n",
      "Episode: 537 Mean test reward: 460.5\n",
      "Episode: 538 Mean test reward: 460.5\n",
      "Episode: 539 Mean test reward: 460.5\n",
      "Episode: 540 Mean test reward: 460.5\n",
      "Episode: 541 Mean test reward: 460.5\n",
      "Episode: 542 Mean test reward: 460.5\n",
      "Episode: 543 Mean test reward: 460.5\n",
      "Episode: 544 Mean test reward: 460.5\n",
      "Episode: 545 Mean test reward: 460.5\n",
      "Episode: 546 Mean test reward: 460.5\n",
      "Episode: 547 Mean test reward: 456.1\n",
      "Episode: 548 Mean test reward: 456.1\n",
      "Episode: 549 Mean test reward: 456.1\n",
      "Episode: 550 Mean test reward: 456.1\n",
      "Episode: 551 Mean test reward: 451.4\n",
      "Episode: 552 Mean test reward: 455.9\n",
      "Episode: 553 Mean test reward: 460.2\n",
      "Episode: 554 Mean test reward: 459.9\n",
      "Episode: 555 Mean test reward: 464.6\n",
      "Episode: 556 Mean test reward: 469.4\n",
      "Episode: 557 Mean test reward: 474.1\n",
      "Episode: 558 Mean test reward: 478.8\n",
      "558 收敛\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_name = \"nips_dqn\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "    set_session(tf.Session(config=config))\n",
    "\n",
    "    train_episodes = 5000  # 1000          # max number of episodes to learn from\n",
    "    max_steps = MAXSTEP  # 200                # max steps in an episode\n",
    "    gamma = 0.99  # future reward discount\n",
    "\n",
    "    # agent parameters\n",
    "    state_size = 4\n",
    "    action_size = 2\n",
    "    # training process\n",
    "    rewards_list = []\n",
    "    test_rewards_list = []\n",
    "    show_every_steps = 100\n",
    "\n",
    "    # Exploration parameters\n",
    "    explore_start = 0.5  # exploration probability at start\n",
    "    explore_stop = 0.01  # minimum S probability\n",
    "    decay_rate = 0.0001  # expotentional decay rate for exploration prob\n",
    "\n",
    "    # Network parameters\n",
    "    hidden_size = 20  # number of units in each Q-network hidden layer\n",
    "\n",
    "\n",
    "    # Memory parameters\n",
    "    memory_size = 10000  # memory capacity\n",
    "    batch_size = 32  # experience mini-batch size\n",
    "    pretrain_length = batch_size  # number experiences to pretrain the memory\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the simulation\n",
    "    env = gym.make('CartPole-v1').env\n",
    "    env.reset()\n",
    "    # Take one random step to get the pole and cart moving\n",
    "    state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    #TODO 指定网络参数和名字\n",
    "    agent = duel_double_dqn(env,maxlen=10000,version=VERSION)\n",
    "    model_name = \"nature_dqn_C5_dueling\"\n",
    "    #memory = Memory(max_size=memorSy_size)\n",
    "\n",
    "    # Make a bunch of random actions and store the experiences\n",
    "    for ii in range(pretrain_length):\n",
    "        # Uncomment the line below to watch the simulation\n",
    "        # env.render()\n",
    "\n",
    "        # Make a random action\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            # The simulation fails so no next state\n",
    "            next_state = np.zeros(state.shape)\n",
    "            # Add experience to memory\n",
    "            agent.store(state, action, reward, next_state, done)\n",
    "\n",
    "            # Start new episode\n",
    "            env.reset()\n",
    "            # Take one random step to get the pole and cart moving\n",
    "            state, reward, done, _ = env.step(env.action_space.sample())\n",
    "        else:\n",
    "            # Add experience to memory\n",
    "            agent.store(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "\n",
    "\n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        #episode_total\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            #env.render()\n",
    "            action = agent.get_action(state)\n",
    "\n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                # Add experience to memory\n",
    "                agent.store(state, action, reward, next_state, done)\n",
    "\n",
    "                # Start new episode\n",
    "                state=env.reset()\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                agent.store(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                t += 1\n",
    "\n",
    "            agent.update()\n",
    "\n",
    "        test_rewards_list.extend(test_agent(agent, env,test_max_steps=MAXSTEP))\n",
    "        cur_compute_len = min(100, len(test_rewards_list))\n",
    "        mean_reward = np.mean(test_rewards_list[len(test_rewards_list) - cur_compute_len:])\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'Mean test reward: {:.1f}'.format(mean_reward), )\n",
    "        if mean_reward > convergence_reward:\n",
    "            print(ep, \"收敛\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478.79000000000002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 17,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 29,\n",
       " 19,\n",
       " 31,\n",
       " 38,\n",
       " 31,\n",
       " 51,\n",
       " 36,\n",
       " 51,\n",
       " 76,\n",
       " 65,\n",
       " 284,\n",
       " 217,\n",
       " 116,\n",
       " 217,\n",
       " 97,\n",
       " 42,\n",
       " 37,\n",
       " 47,\n",
       " 40,\n",
       " 43,\n",
       " 88,\n",
       " 27,\n",
       " 34,\n",
       " 27,\n",
       " 34,\n",
       " 26,\n",
       " 21,\n",
       " 18,\n",
       " 23,\n",
       " 29,\n",
       " 37,\n",
       " 22,\n",
       " 16,\n",
       " 17,\n",
       " 22,\n",
       " 29,\n",
       " 21,\n",
       " 52,\n",
       " 30,\n",
       " 49,\n",
       " 70,\n",
       " 59,\n",
       " 78,\n",
       " 65,\n",
       " 41,\n",
       " 64,\n",
       " 79,\n",
       " 96,\n",
       " 500,\n",
       " 105,\n",
       " 146,\n",
       " 86,\n",
       " 134,\n",
       " 122,\n",
       " 113,\n",
       " 375,\n",
       " 160,\n",
       " 160,\n",
       " 221,\n",
       " 469,\n",
       " 252,\n",
       " 367,\n",
       " 372,\n",
       " 393,\n",
       " 289,\n",
       " 280,\n",
       " 387,\n",
       " 393,\n",
       " 228,\n",
       " 500,\n",
       " 428,\n",
       " 500,\n",
       " 500,\n",
       " 439,\n",
       " 295,\n",
       " 300,\n",
       " 268,\n",
       " 500,\n",
       " 394,\n",
       " 494,\n",
       " 450,\n",
       " 412,\n",
       " 500,\n",
       " 267,\n",
       " 253,\n",
       " 318,\n",
       " 339,\n",
       " 500,\n",
       " 352,\n",
       " 444,\n",
       " 500,\n",
       " 357,\n",
       " 279,\n",
       " 500,\n",
       " 500,\n",
       " 277,\n",
       " 345,\n",
       " 391,\n",
       " 250,\n",
       " 249,\n",
       " 489,\n",
       " 235,\n",
       " 266,\n",
       " 251,\n",
       " 270,\n",
       " 215,\n",
       " 472,\n",
       " 229,\n",
       " 447,\n",
       " 299,\n",
       " 206,\n",
       " 266,\n",
       " 273,\n",
       " 333,\n",
       " 500,\n",
       " 239,\n",
       " 262,\n",
       " 500,\n",
       " 500,\n",
       " 420,\n",
       " 500,\n",
       " 414,\n",
       " 458,\n",
       " 243,\n",
       " 224,\n",
       " 373,\n",
       " 269,\n",
       " 428,\n",
       " 500,\n",
       " 273,\n",
       " 278,\n",
       " 500,\n",
       " 334,\n",
       " 407,\n",
       " 500,\n",
       " 373,\n",
       " 362,\n",
       " 291,\n",
       " 328,\n",
       " 500,\n",
       " 500,\n",
       " 229,\n",
       " 254,\n",
       " 409,\n",
       " 500,\n",
       " 253,\n",
       " 306,\n",
       " 345,\n",
       " 500,\n",
       " 289,\n",
       " 260,\n",
       " 500,\n",
       " 313,\n",
       " 255,\n",
       " 310,\n",
       " 319,\n",
       " 471,\n",
       " 397,\n",
       " 324,\n",
       " 247,\n",
       " 500,\n",
       " 361,\n",
       " 257,\n",
       " 398,\n",
       " 219,\n",
       " 363,\n",
       " 405,\n",
       " 342,\n",
       " 309,\n",
       " 327,\n",
       " 312,\n",
       " 414,\n",
       " 500,\n",
       " 415,\n",
       " 443,\n",
       " 306,\n",
       " 358,\n",
       " 261,\n",
       " 300,\n",
       " 500,\n",
       " 252,\n",
       " 368,\n",
       " 479,\n",
       " 374,\n",
       " 364,\n",
       " 484,\n",
       " 355,\n",
       " 264,\n",
       " 329,\n",
       " 284,\n",
       " 433,\n",
       " 331,\n",
       " 333,\n",
       " 276,\n",
       " 276,\n",
       " 368,\n",
       " 500,\n",
       " 358,\n",
       " 500,\n",
       " 358,\n",
       " 321,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 388,\n",
       " 444,\n",
       " 373,\n",
       " 451,\n",
       " 500,\n",
       " 500,\n",
       " 341,\n",
       " 500,\n",
       " 500,\n",
       " 458,\n",
       " 500,\n",
       " 500,\n",
       " 492,\n",
       " 355,\n",
       " 330,\n",
       " 451,\n",
       " 415,\n",
       " 346,\n",
       " 500,\n",
       " 471,\n",
       " 441,\n",
       " 466,\n",
       " 423,\n",
       " 412,\n",
       " 496,\n",
       " 500,\n",
       " 451,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 400,\n",
       " 424,\n",
       " 311,\n",
       " 434,\n",
       " 500,\n",
       " 431,\n",
       " 440,\n",
       " 422,\n",
       " 500,\n",
       " 366,\n",
       " 300,\n",
       " 343,\n",
       " 500,\n",
       " 415,\n",
       " 315,\n",
       " 500,\n",
       " 380,\n",
       " 299,\n",
       " 251,\n",
       " 321,\n",
       " 467,\n",
       " 245,\n",
       " 500,\n",
       " 272,\n",
       " 313,\n",
       " 321,\n",
       " 405,\n",
       " 387,\n",
       " 446,\n",
       " 500,\n",
       " 421,\n",
       " 243,\n",
       " 500,\n",
       " 241,\n",
       " 492,\n",
       " 500,\n",
       " 425,\n",
       " 409,\n",
       " 500,\n",
       " 500,\n",
       " 311,\n",
       " 500,\n",
       " 276,\n",
       " 278,\n",
       " 292,\n",
       " 500,\n",
       " 500,\n",
       " 246,\n",
       " 325,\n",
       " 500,\n",
       " 372,\n",
       " 312,\n",
       " 301,\n",
       " 212,\n",
       " 331,\n",
       " 500,\n",
       " 285,\n",
       " 237,\n",
       " 256,\n",
       " 235,\n",
       " 247,\n",
       " 256,\n",
       " 255,\n",
       " 221,\n",
       " 262,\n",
       " 257,\n",
       " 322,\n",
       " 275,\n",
       " 229,\n",
       " 307,\n",
       " 240,\n",
       " 332,\n",
       " 284,\n",
       " 277,\n",
       " 500,\n",
       " 280,\n",
       " 259,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 285,\n",
       " 500,\n",
       " 403,\n",
       " 356,\n",
       " 356,\n",
       " 468,\n",
       " 373,\n",
       " 500,\n",
       " 436,\n",
       " 500,\n",
       " 388,\n",
       " 500,\n",
       " 500,\n",
       " 329,\n",
       " 413,\n",
       " 310,\n",
       " 500,\n",
       " 439,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 456,\n",
       " 425,\n",
       " 500,\n",
       " 456,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 485,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 51,\n",
       " 77,\n",
       " 37,\n",
       " 25,\n",
       " 27,\n",
       " 28,\n",
       " 31,\n",
       " 35,\n",
       " 265,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 479,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 494,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 58,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 38,\n",
       " 500,\n",
       " 500,\n",
       " 10,\n",
       " 500,\n",
       " 500,\n",
       " 500,\n",
       " 500]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923\n"
     ]
    }
   ],
   "source": [
    "reward_list = []\n",
    "test_max_steps = convergence_reward + 5\n",
    "\n",
    "state = env.reset()\n",
    "t = 0\n",
    "while True:\n",
    "    env.render()\n",
    "    action = agent.get_action(state,False)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "    else:\n",
    "        state = next_state\n",
    "        t += 1\n",
    "            \n",
    "            \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nips 372 553\n",
    "#nips dueling 414 558\n",
    "#nature 359 328\n",
    "#nature dueling 300 330\n",
    "#double 338 394\n",
    "#double dueling  306 366 350"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
